#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Dialect TTS Zero Shot Inference Gradio Interface
Integrating text frontend processing and TTS model inference
"""

import os
import sys
import tempfile
import shutil
import subprocess
import argparse
import codecs
from pathlib import Path
from datetime import datetime
import numpy as np
import soundfile as sf
import gradio as gr
import torch
from omegaconf import OmegaConf
from hydra.utils import get_class

# Ê∑ªÂä†Ë∑ØÂæÑ
sys.path.insert(0, "./dialect_frontend")
sys.path.insert(0, "./diamoe_tts/src")

# ‰ªédialect_frontendÂØºÂÖ•ÂøÖË¶ÅÁöÑÊ®°Âùó
from tools.mix_wrapper import Preprocessor

# ‰ªéTTSÊ®°ÂùóÂØºÂÖ•
from f5_tts.infer.utils_infer import (
    mel_spec_type,
    target_rms,
    cross_fade_duration,
    nfe_step,
    cfg_strength,
    sway_sampling_coef,
    speed,
    fix_duration,
    device,
    infer_process,
    load_model,
    load_vocoder,
    preprocess_ref_audio_text,
    remove_silence_for_generated_wav,
)

# Ê®°ÂûãÈÖçÁΩÆÂèÇÊï∞ - Âú®ËøôÈáåÁõ¥Êé•ÊåáÂÆö
MODEL_CONFIG = {
    "model_name": "gradio",
    "ckpt_file": "/path/to/your/model.pt",  # ËØ∑‰øÆÊîπ‰∏∫‰Ω†ÁöÑÊ®°ÂûãË∑ØÂæÑ
    "vocab_file": "./diamoe_tts/data/vocab.txt",
    "use_moe": True,
    "num_exps": 9,
    "moe_topK": 1,
    "expert_type": "mlp"
}
 
class DialectTTSPipeline:
    """ÊñπË®ÄTTSÂ§ÑÁêÜÁÆ°ÈÅì"""
    
    def __init__(self, auto_load_model=True):
        self.dialect_list = [
            "putonghua", "chengdu", "gaoxiong", "shanghai",
            "shijiazhuang", "wuhan", "xian", "zhengzhou"
        ]
        # ÂàùÂßãÂåñÂâçÁ´ØÂ§ÑÁêÜÂô®
        self.preprocessor = Preprocessor()
        self.frontend = self.preprocessor.frontend['ZH']
        print("Frontend processor initialized!")
        
        # Âä†ËΩΩIPAÈü≥Á¥†ÂàóË°®ÂíåÊ†áÁÇπÁ¨¶Âè∑
        self.load_vocab_and_punctuation()
        
        # Ê®°ÂûãÁõ∏ÂÖ≥ÂèòÈáè
        self.model = None
        self.vocoder = None
        self.model_loaded = False
        
        # Ëá™Âä®Âä†ËΩΩÊ®°Âûã
        if auto_load_model:
            self.load_tts_model(
                model_name=MODEL_CONFIG["model_name"],
                ckpt_file=MODEL_CONFIG["ckpt_file"],
                vocab_file=MODEL_CONFIG["vocab_file"],
                use_moe=MODEL_CONFIG["use_moe"],
                num_exps=MODEL_CONFIG["num_exps"],
                moe_topK=MODEL_CONFIG["moe_topK"],
                expert_type=MODEL_CONFIG["expert_type"]
            )
          
    def load_vocab_and_punctuation(self):
        """Âä†ËΩΩIPAÈü≥Á¥†ÂàóË°®ÂíåÊ†áÁÇπÁ¨¶Âè∑"""
        try:
            # Âä†ËΩΩËØçÊ±áË°®
            with open(MODEL_CONFIG["vocab_file"], 'r', encoding='utf-8') as f:
                vocab_lines = [line.strip() for line in f if line.strip()]
            
            # ËøáÊª§Âá∫Áî®[]ÂåÖË£ÖÁöÑÈü≥Á¥†
            self.ipa_list = []
            for line in vocab_lines:
                if line.startswith('[') and line.endswith(']'):
                    self.ipa_list.append(line)
            
            # Âä†ËΩΩÊ†áÁÇπÁ¨¶Âè∑
            punctuation_path = "./diamoe_tts/data/punctuation.txt"
            if os.path.exists(punctuation_path):
                with open(punctuation_path, 'r', encoding='utf-8') as f:
                    self.punctuation_list = [line.strip() for line in f if line.strip()]
            else:
                self.punctuation_list = []
            
            print(f"Loaded {len(self.ipa_list)} IPA phonemes and {len(self.punctuation_list)} punctuation marks")
            
        except Exception as e:
            print(f"Failed to load vocabulary: {e}")
            self.ipa_list = []
            self.punctuation_list = []
    
    def convert_to_ipa_format(self, text: str) -> str:
        """Â∞ÜÂâçÁ´ØÂ§ÑÁêÜÁöÑÊñáÊú¨ËΩ¨Êç¢‰∏∫IPAÊ†ºÂºè"""
        if not text or not text.strip():
            return text
        
        # ÂèÇËÄÉprepare_ipa.pyÁöÑÂÆûÁé∞
        # Áî®Á©∫Ê†ºÂàÜÂâ≤ÂæóÂà∞tokenÂàóË°®
        target_text = text.split(" ")
        
        ipa_text = []
        for it in target_text:
            # Ë∑≥ËøáÁ©∫token
            if not it.strip():
                continue
                
            it = it.strip()
            symbol = '[' + it + ']'
            
            if symbol in self.ipa_list:
                # Â¶ÇÊûúÊòØÊúâÊïàÁöÑIPAÈü≥Á¥†ÔºåÊ∑ªÂä†[token]Ê†ºÂºè
                ipa_text.append(symbol)
            elif symbol in self.punctuation_list:
                # Â¶ÇÊûúÊòØÊ†áÁÇπÁ¨¶Âè∑ÔºåÊ∑ªÂä†ÂéüÂßãtokenÔºà‰∏çÂä†‰∏≠Êã¨Âè∑Ôºâ
                ipa_text.append(it)
            else:
                # Ë∑≥ËøáÁ©∫Á¨¶Âè∑Âíå|Á¨¶Âè∑
                if symbol != '[]' and symbol != '[|]':
                    print(f'Warning: Unknown symbol {symbol}')
                # Ë∑≥ËøáÊú™Áü•Á¨¶Âè∑
                continue
        
        result = ' '.join(ipa_text)
        print(f"IPA format conversion: {text[:50]}... -> {result[:50]}...")
        return result
    
    def replace_english_punctuation_with_chinese(self, text: str) -> str:
        """Â∞ÜËã±ÊñáÊ†áÁÇπËΩ¨Êç¢‰∏∫‰∏≠ÊñáÊ†áÁÇπ"""
        en_to_zh_punct = {",": "Ôºå", ".": "„ÄÇ", "?": "Ôºü", "!": "ÔºÅ", ":": "Ôºö", ";": "Ôºõ",
            "(": "Ôºà", ")": "Ôºâ", "[": "„Äê", "]": "„Äë", "{": "ÔΩõ", "}": "ÔΩù",
            "<": "„Ää", ">": "„Äã", '\"': '"', "'": "'", "-": "Ôºç", "_": "Ôºø",
            "&": "ÔºÜ", "@": "Ôº†", "/": "Ôºè", "\\": "„ÄÅ", "|": "ÔΩú",
            "`": "ÔΩÄ", "~": "ÔΩû", "^": "Ôºæ"}
        
        
        for en, zh in en_to_zh_punct.items():
            text = text.replace(en, zh)
        return text
    
    def process_text_to_pinyin(self, text: str) -> tuple:
        """Â§ÑÁêÜÊñáÊú¨Âà∞ÊãºÈü≥ÁöÑËΩ¨Êç¢ÔºåÁõ¥Êé•‰ΩøÁî®Â∑≤Âä†ËΩΩÁöÑÂâçÁ´ØÂ§ÑÁêÜÂô®"""
        try:
            # ‰ΩøÁî®ÂâçÁ´ØÂ§ÑÁêÜÂô®ËΩ¨Êç¢ÊñáÊú¨Âà∞ÊãºÈü≥
            phones_list, word2ph, tones_list, ppinyins, oop, zhongwens = self.frontend.get_splited_phonemes_tones([text])
            
            # Ê†áÁÇπÁ¨¶Âè∑ËΩ¨Êç¢
            zhongwens = self.replace_english_punctuation_with_chinese(zhongwens)
            ppinyins = self.replace_english_punctuation_with_chinese(ppinyins)
            
            print(f"Text to pinyin: {text} -> {ppinyins}")
            return zhongwens, ppinyins, oop
        except Exception as e:
            print(f"Pinyin conversion error: {e}")
            return text, text, []
    
    def run_shell_command(self, command: str, cwd: str = None) -> tuple:
        """ËøêË°åshellÂëΩ‰ª§"""
        try:
            result = subprocess.run(
                command, 
                shell=True, 
                capture_output=True, 
                text=True, 
                cwd=cwd,
                encoding='utf-8'
            )
            return result.returncode, result.stdout, result.stderr
        except Exception as e:
            return 1, "", str(e)
    
    def create_temp_file(self, content: str, suffix: str = ".txt") -> str:
        """ÂàõÂª∫‰∏¥Êó∂Êñá‰ª∂"""
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix=suffix, delete=False, encoding='utf-8')
        temp_file.write(content)
        temp_file.close()
        return temp_file.name
    
    def process_frontend_pipeline(self, text: str, dialect: str) -> str:
        """ÂÆåÊï¥ÁöÑÂâçÁ´ØÂ§ÑÁêÜÁÆ°ÈÅì"""
        print(f"Starting dialect frontend processing: {dialect}")
        
        # ÂàõÂª∫‰∏¥Êó∂ÁõÆÂΩï
        temp_dir = tempfile.mkdtemp()
        try:
            # Ê≠•È™§1: Áõ¥Êé•‰ΩøÁî®Â∑≤Âä†ËΩΩÁöÑÂâçÁ´ØÂ§ÑÁêÜÂô®ÁîüÊàêÊãºÈü≥
            print("Executing pinyin conversion...")
            zhongwens, ppinyins, oop = self.process_text_to_pinyin(text)
            
            # Ê≠•È™§2: ÂàõÂª∫ÊãºÈü≥Êñá‰ª∂‰æõÂêéÁª≠Â§ÑÁêÜ
            pinyin_file = os.path.join(temp_dir, "pinyin_output.txt")
            with open(pinyin_file, 'w', encoding='utf-8') as f:
                f.write(f"temp_id\t{zhongwens}\t{ppinyins}\n")
             
            # Ê≠•È™§3: ËøêË°åÊñπË®ÄÂâçÁ´ØÂ§ÑÁêÜËÑöÊú¨
            if dialect == "putonghua":
                # ÊôÆÈÄöËØùÁõ¥Êé•‰ΩøÁî®ÊãºÈü≥ÁªìÊûú
                final_output = pinyin_file
            else:
                # ËøêË°åsingle_frontend.shËÑöÊú¨Ôºå‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
                current_dir = os.getcwd()
                dialect_dir = os.path.join(current_dir, "dialect_frontend")
                script_path = os.path.join(dialect_dir, "single_frontend.sh")
                
                # Ê£ÄÊü•ËÑöÊú¨Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
                if not os.path.exists(script_path):
                    print(f"Script file does not exist: {script_path}")
                    print(f"Current working directory: {current_dir}")
                    print(f"Trying to list dialect_frontend directory contents:")
                    try:
                        files = os.listdir(dialect_dir) if os.path.exists(dialect_dir) else ["Directory does not exist"]
                        print(files)
                    except:
                        print("Cannot list directory contents")
                    final_output = pinyin_file
                else:
                    # ‰ΩøÁî®Áõ∏ÂØπË∑ØÂæÑÂú®dialect_frontendÁõÆÂΩï‰∏ãÊâßË°å
                    frontend_command = f'bash single_frontend.sh all {dialect} "{os.path.basename(pinyin_file)}"'
                    print(f"Executing frontend processing: {frontend_command}")
                    print(f"Working directory: {dialect_dir}")
                    
                    # Â§çÂà∂Êñá‰ª∂Âà∞dialect_frontendÁõÆÂΩï‰ª•‰æøËÑöÊú¨Â§ÑÁêÜ
                    temp_pinyin_file = os.path.join(dialect_dir, os.path.basename(pinyin_file))
                    try:
                        shutil.copy2(pinyin_file, temp_pinyin_file)
                        print(f"File copied to: {temp_pinyin_file}")
                    except Exception as e:
                        print(f"File copy failed: {e}")
                    
                    # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè
                    env = os.environ.copy()
                    env['LANG'] = 'C.UTF-8'
                    env['LC_ALL'] = 'C.UTF-8'
                    
                    try:
                        result = subprocess.run(
                            frontend_command,
                            shell=True,
                            capture_output=True,
                            text=True,
                            cwd=dialect_dir,  # Âú®dialect_frontendÁõÆÂΩï‰∏ãÊâßË°å
                            env=env,
                            encoding='utf-8'
                        )
                        ret_code, stdout, stderr = result.returncode, result.stdout, result.stderr
                    except Exception as e:
                        ret_code, stdout, stderr = 1, "", str(e)
                
                    if ret_code != 0:
                        print(f"Frontend processing failed: {stderr}")
                        print(f"Standard output: {stdout}")
                        # ‰ΩøÁî®ÂéüÂßãÊãºÈü≥Êñá‰ª∂‰Ωú‰∏∫ÂõûÈÄÄ
                        final_output = pinyin_file
                    else:
                        # Êü•ÊâæÊúÄÁªàÁöÑIPAÊ†ºÂºèÊñá‰ª∂ÔºàÂú®dialect_frontendÁõÆÂΩï‰∏ãÔºâ
                        base_name = os.path.splitext(temp_pinyin_file)[0]
                        ipa_file = base_name + "_ipa_format.txt"
                        if os.path.exists(ipa_file):
                            # Â∞ÜÁªìÊûúÊñá‰ª∂Â§çÂà∂Âõû‰∏¥Êó∂ÁõÆÂΩï
                            final_output = os.path.join(temp_dir, "final_ipa_format.txt")
                            try:
                                shutil.copy2(ipa_file, final_output)
                                print(f"Result file copied to: {final_output}")
                            except Exception as e:
                                print(f"Result file copy failed: {e}")
                                final_output = pinyin_file
                        else:
                            print("IPA format file not found, using pinyin file")
                            final_output = pinyin_file
            
            # ËØªÂèñÊúÄÁªàÁªìÊûú
            if os.path.exists(final_output):
                with open(final_output, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        # ÂèñÊúÄÂêé‰∏ÄÂàó‰Ωú‰∏∫Â§ÑÁêÜÂêéÁöÑÈü≥Á¥†
                        parts = lines[0].strip().split('\t')
                        if len(parts) >= 3:
                            return parts[-1]  # ÊúÄÂêé‰∏ÄÂàóÊòØÂ§ÑÁêÜÂêéÁöÑÈü≥Á¥†
                        else:
                            return parts[1] if len(parts) > 1 else text
                    else:
                        return text
            else:
                print(f"Output file does not exist: {final_output}")
                return text
                
        except Exception as e:
            print(f"Frontend processing error: {e}")
            return text
        finally:
            # Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
            try:
                shutil.rmtree(temp_dir)
            except:
                pass
    
    def load_tts_model(self, model_name: str = "test", 
                      ckpt_file: str = "", 
                      vocab_file: str = "./diamoe_tts/data/vocab.txt",
                      use_moe: bool = True,
                      num_exps: int = 9,
                      moe_topK: int = 1,
                      expert_type: str = "mlp"):
        """Âä†ËΩΩTTSÊ®°Âûã"""
        try:
            print("Starting to load TTS model...")
            
            # Âä†ËΩΩvocoder
            vocoder_name = mel_spec_type
            if vocoder_name == "vocos":
                vocoder_local_path = "./checkpoints/vocos-mel-24khz"
            elif vocoder_name == "bigvgan":
                vocoder_local_path = "./checkpoints/bigvgan_v2_24khz_100band_256x"
            else:
                vocoder_local_path = ""
            
            self.vocoder = load_vocoder(
                vocoder_name=vocoder_name, 
                is_local=False, 
                local_path=vocoder_local_path, 
                device=device
            )
            print("Vocoder loaded successfully!")
            
            # Âä†ËΩΩTTSÊ®°Âûã
            model_cfg_path = f"./diamoe_tts/src/f5_tts/configs/{model_name}.yaml"
            if not os.path.exists(model_cfg_path):
                model_cfg_path = "./diamoe_tts/src/f5_tts/configs/diamoetts.yaml"
            
            model_cfg = OmegaConf.load(model_cfg_path)
            model_cls = get_class(f"f5_tts.model.{model_cfg.model.backbone}")
            model_arc = model_cfg.model.arch
            
            print(f"Using model config: {model_cfg_path}")
            print(f"Model class: {model_cls}, architecture: {model_arc}")
            
            if ckpt_file and os.path.exists(ckpt_file):
                print(f"Loading model from checkpoint: {ckpt_file}")
                self.model = load_model(
                    model_cls, model_arc, ckpt_file, 
                    mel_spec_type=vocoder_name, 
                    vocab_file=vocab_file, 
                    device=device,
                    use_moe=use_moe, 
                    num_exps=num_exps, 
                    moe_topK=moe_topK, 
                    expert_type=expert_type.lower()
                )
                self.model_loaded = True
                print("TTS model loaded successfully!")
            else:
                print("No valid model checkpoint file provided")
                self.model_loaded = False
                
        except Exception as e:
            print(f"Model loading failed: {e}")
            self.model_loaded = False
    
    def synthesize_speech(self, text: str, dialect: str, 
                         ref_audio_path: str, ref_text: str,
                         target_rms: float = 0.1,
                         cross_fade_duration: float = 0.15,
                         nfe_step: int = 32,
                         cfg_strength: float = 2.0,
                         sway_sampling_coef: float = -1.0,
                         speed: float = 1.0) -> tuple:
        """ÂêàÊàêËØ≠Èü≥"""
        if not self.model_loaded:
            return None, "Model not loaded, please load model first"
        
        try:
            print(f"Starting speech synthesis: {dialect}")
            print(f"Input text: {text}")
            
            # Ê≠•È™§1: ÂâçÁ´ØÂ§ÑÁêÜ
            processed_text = self.process_frontend_pipeline(text, dialect)
            print(f"Frontend processing result: {processed_text}")
            
            # Ê≠•È™§2: È¢ÑÂ§ÑÁêÜÂèÇËÄÉÈü≥È¢ëÂíåÊñáÊú¨
            ref_audio, ref_text_processed = preprocess_ref_audio_text(ref_audio_path, ref_text)
            print(f"Reference audio processing completed")
            
            # Ê≠•È™§3: IPAÊ†ºÂºèËΩ¨Êç¢
            # ÂØπÁîüÊàêÊñáÊú¨ËøõË°åÊ†ºÂºèËΩ¨Êç¢
            processed_text_ipa = self.convert_to_ipa_format(processed_text)
            
            # ÂØπÂèÇËÄÉÊñáÊú¨‰πüËøõË°åÂâçÁ´ØÂ§ÑÁêÜÂíåÊ†ºÂºèËΩ¨Êç¢
            if ref_text_processed and ref_text_processed.strip():
                # È¶ñÂÖàÂØπÂèÇËÄÉÊñáÊú¨ËøõË°åÂâçÁ´ØÂ§ÑÁêÜ
                ref_processed = self.process_frontend_pipeline(ref_text_processed, dialect)
                # ÁÑ∂ÂêéËøõË°åIPAÊ†ºÂºèËΩ¨Êç¢
                ref_text_processed_ipa = self.convert_to_ipa_format(ref_processed)
            else:
                ref_text_processed_ipa = ref_text_processed
            
            print(f"IPA format conversion - Generated text: {processed_text_ipa}")
            print(f"IPA format conversion - Reference text: {ref_text_processed_ipa}")
            
            # Ê≠•È™§4: ËøõË°åTTSÊé®ÁêÜ
            audio_segment, final_sample_rate, spectrogram = infer_process(
                ref_audio,
                ref_text_processed_ipa,
                processed_text_ipa,
                self.model,
                self.vocoder,
                mel_spec_type=mel_spec_type,
                target_rms=target_rms,
                cross_fade_duration=cross_fade_duration,
                nfe_step=nfe_step,
                cfg_strength=cfg_strength,
                sway_sampling_coef=sway_sampling_coef,
                speed=speed,
                fix_duration=None,
                device=device,
            )
            
            # ‰øùÂ≠òÈü≥È¢ë
            output_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            sf.write(output_file.name, audio_segment, final_sample_rate)
            
            return output_file.name, "Synthesis successful!"
            
        except Exception as e:
            print(f"Speech synthesis failed: {e}")
            return None, f"Synthesis failed: {str(e)}"
    
    def generate_frontend_only(self, text: str, dialect: str) -> tuple:
        """Generate frontend processing only without TTS"""
        try:
            print(f"Starting frontend-only processing: {dialect}")
            print(f"Input text: {text}")
            
            # Áõ¥Êé•Ë∞ÉÁî®ÂÆåÊï¥ÁöÑÂâçÁ´ØÂ§ÑÁêÜÁÆ°ÈÅìÔºå‰º†ÂÖ•Á∫ØÂáÄÁöÑÁî®Êà∑ÊñáÊú¨
            processed_text = self.process_frontend_pipeline(text, dialect)
            print(f"Frontend processing result: {processed_text}")
            
            # IPAÊ†ºÂºèËΩ¨Êç¢
            processed_text_ipa = self.convert_to_ipa_format(processed_text)
            print(f"IPA format result: {processed_text_ipa}")
            
            return processed_text, processed_text_ipa, "Frontend processing successful!"
            
        except Exception as e:
            print(f"Frontend processing failed: {e}")
            return text, text, f"Frontend processing failed: {str(e)}"

# Global pipeline instance - preload model
print("Initializing Dialect TTS pipeline and preloading model...")
pipeline = DialectTTSPipeline(auto_load_model=True)

# Sample texts for different languages
SAMPLE_TEXTS = {
    "Chinese": [
        "‰Ω†Â•ΩÔºåÊ¨¢Ëøé‰ΩøÁî®ÊñπË®ÄËØ≠Èü≥ÂêàÊàêÁ≥ªÁªü„ÄÇ",
        "‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÈò≥ÂÖâÊòéÂ™ö„ÄÇ",
        "Êò•Áú†‰∏çËßâÊôìÔºåÂ§ÑÂ§ÑÈóªÂïºÈ∏ü„ÄÇ",
        "Â±±ÈáçÊ∞¥Â§çÁñëÊó†Ë∑ØÔºåÊü≥ÊöóËä±ÊòéÂèà‰∏ÄÊùë„ÄÇ",
        "Êµ∑ÂÜÖÂ≠òÁü•Â∑±ÔºåÂ§©Ê∂ØËã•ÊØîÈÇª„ÄÇ"
    ]
}

# Sample reference audios for each dialect (male and female versions)
SAMPLE_REFERENCE_AUDIOS = {
    "putonghua": {
        "male": "prompts/putonghua_male_prompt.wav",
        "female": "prompts/putonghua_female_prompt.wav"
    },
    "chengdu": {
        "male": "prompts/chengdu_male_prompt.wav",
        "female": "prompts/chengdu_female_prompt.wav"
    },
    "gaoxiong": {
        "male": "prompts/hokkien_male_prompt.wav",
        "female": "prompts/hokkien_female_prompt.wav"
    },
    "nanjing": {
        "male": "prompts/nanjing_male_prompt.wav",
        "female": "prompts/nanjing_female_prompt.wav"
    },
    "shanghai": {
        "male": "prompts/shanghai_male_prompt.wav",
        "female": "prompts/shanghai_female_prompt.wav"
    },
    "shijiazhuang": {
        "male": "prompts/shijiazhuang_male_prompt.wav",
        "female": "prompts/shijiazhuang_female_prompt.wav"
    },
    "tianjin": {
        "male": "prompts/tianjin_male_prompt.wav",
        "female": "prompts/tianjin_female_prompt.wav"
    },
    "xian": {
        "male": "prompts/xian_male_prompt.wav",
        "female": "prompts/xian_female_prompt.wav"
    },
    "zhengzhou": {
        "male": "prompts/zhengzhou_male_prompt.wav",
        "female": "prompts/zhengzhou_female_prompt.wav"
    }
}

def create_gradio_interface():
    """Create Gradio interface"""
    
    def synthesize_interface(text, dialect, ref_audio, ref_text, 
                           target_rms, nfe_step, speed):
        """Interface function for speech synthesis"""
        if not text.strip():
            return None, "Please enter text to synthesize"
        
        if not ref_audio:
            return None, "Please upload reference audio"
        
        if not ref_text.strip():
            return None, "Please enter reference text"
        
        audio_file, message = pipeline.synthesize_speech(
            text=text,
            dialect=dialect,
            ref_audio_path=ref_audio,
            ref_text=ref_text,
            target_rms=target_rms,
            cross_fade_duration=0.15,  # Fixed value
            nfe_step=nfe_step,
            cfg_strength=2.0,  # Fixed value
            sway_sampling_coef=-1.0,  # Fixed value
            speed=speed
        )
        
        return audio_file, message
    
    def frontend_only_interface(text, dialect):
        """Interface function for frontend processing only"""
        if not text.strip():
            return "", "", "Please enter text to process"
        
        processed_text, ipa_text, message = pipeline.generate_frontend_only(text, dialect)
        return processed_text, ipa_text, message
    
    def update_sample_text(sample_text):
        """Update text input with selected sample"""
        return sample_text
    
    def update_sample_audio_male(dialect):
        """Update reference audio and text with male sample for selected dialect"""
        dialect_samples = SAMPLE_REFERENCE_AUDIOS.get(dialect, {})
        audio_path = dialect_samples.get("male", "")
        
        ref_text = ""
        if audio_path and os.path.exists(audio_path):
            # ËØªÂèñÂØπÂ∫îÁöÑtxtÊñá‰ª∂
            txt_path = audio_path.replace('.wav', '.txt')
            if os.path.exists(txt_path):
                try:
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        line = f.readline().strip()
                        # Ëß£ÊûêÊ†ºÂºè: TEXT\tÊñáÊú¨ÂÜÖÂÆπ\tIPAÂÜÖÂÆπ
                        parts = line.split('\t')
                        if len(parts) >= 3:
                            ref_text = parts[1]  # ÊèêÂèñ‰∏≠Èó¥ÁöÑÊñáÊú¨ÈÉ®ÂàÜ
                        elif len(parts) == 2:
                            ref_text = parts[1]  # ÂÖºÂÆπÂè™Êúâ‰∏§ÂàóÁöÑÊÉÖÂÜµ
                except Exception as e:
                    print(f"Error reading reference text from {txt_path}: {e}")
            
            return audio_path, ref_text
        else:
            return None, ""
    
    def update_sample_audio_female(dialect):
        """Update reference audio and text with female sample for selected dialect"""
        dialect_samples = SAMPLE_REFERENCE_AUDIOS.get(dialect, {})
        audio_path = dialect_samples.get("female", "")
        
        ref_text = ""
        if audio_path and os.path.exists(audio_path):
            # ËØªÂèñÂØπÂ∫îÁöÑtxtÊñá‰ª∂
            txt_path = audio_path.replace('.wav', '.txt')
            if os.path.exists(txt_path):
                try:
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        line = f.readline().strip()
                        # Ëß£ÊûêÊ†ºÂºè: TEXT\tÊñáÊú¨ÂÜÖÂÆπ\tIPAÂÜÖÂÆπ
                        parts = line.split('\t')
                        if len(parts) >= 3:
                            ref_text = parts[1]  # ÊèêÂèñ‰∏≠Èó¥ÁöÑÊñáÊú¨ÈÉ®ÂàÜ
                        elif len(parts) == 2:
                            ref_text = parts[1]  # ÂÖºÂÆπÂè™Êúâ‰∏§ÂàóÁöÑÊÉÖÂÜµ
                except Exception as e:
                    print(f"Error reading reference text from {txt_path}: {e}")
            
            return audio_path, ref_text
        else:
            return None, ""
    
    # Create interface
    with gr.Blocks(title="DiaMoE-TTS") as demo:
        gr.Markdown("# üéôÔ∏è DiaMoE-TTS")
        gr.Markdown("This is a zero-shot dialect speech synthesis system supporting multiple Chinese dialects")
        
        # Display model status
        with gr.Row():
            model_status_display = gr.Markdown(
                f"**Model Status**: {'‚úÖ Loaded' if pipeline.model_loaded else '‚ùå Not Loaded'} | "
                f"**Model Config**: {MODEL_CONFIG['model_name']} | "
                f"**MoE**: {'Yes' if MODEL_CONFIG['use_moe'] else 'No'} "
                f"({MODEL_CONFIG['num_exps']} experts, Top{MODEL_CONFIG['moe_topK']})"
            )
        
        with gr.Tab("Frontend Processing"):
            gr.Markdown("## Text Frontend Processing Only")
            gr.Markdown("Generate phonetic representation without TTS synthesis")
            
            with gr.Row():
                with gr.Column():
                    frontend_text_input = gr.Textbox(
                        label="Input Text (Chinese text input supported)", 
                        placeholder="Please enter Chinese text to process...",
                        lines=3
                    )
                    
                    frontend_dialect_choice = gr.Dropdown(
                        label="Select Dialect (Choose dialect type for processing)", 
                        choices=pipeline.dialect_list,
                        value="putonghua"
                    )
                    
                    frontend_process_btn = gr.Button("üî§ Process Frontend", variant="primary")
                
                with gr.Column():
                    processed_output = gr.Textbox(
                        label="Processed Text", 
                        interactive=False,
                        lines=3
                    )
                    
                    ipa_output = gr.Textbox(
                        label="IPA Format", 
                        interactive=False,
                        lines=3
                    )
                    
                    frontend_status = gr.Textbox(
                        label="Processing Status", 
                        interactive=False
                    )
            
            frontend_process_btn.click(
                fn=frontend_only_interface,
                inputs=[frontend_text_input, frontend_dialect_choice],
                outputs=[processed_output, ipa_output, frontend_status]
            )
        
        with gr.Tab("Speech Synthesis"):
            gr.Markdown("## Zero-Shot Speech Synthesis")
            
            with gr.Row():
                with gr.Column():
                    # Sample text selection
                    gr.Markdown("### Sample Texts")
                    sample_text_buttons = []
                    for text in SAMPLE_TEXTS["Chinese"]:
                        btn = gr.Button(text[:20] + "..." if len(text) > 20 else text, size="sm")
                        sample_text_buttons.append((btn, text))
                    
                    text_input = gr.Textbox(
                        label="Input Text (Chinese text input supported)", 
                        placeholder="Please enter Chinese text to synthesize...",
                        lines=3
                    )
                    
                    dialect_choice = gr.Dropdown(
                        label="Select Dialect (Choose dialect type for synthesis)", 
                        choices=pipeline.dialect_list,
                        value="putonghua"
                    )
                    
                    # Sample reference audio buttons
                    gr.Markdown("### Reference Audio")
                    with gr.Row():
                        sample_audio_male_btn = gr.Button("üìÅ Use Sample Audio (Male)", size="sm")
                        sample_audio_female_btn = gr.Button("üìÅ Use Sample Audio (Female)", size="sm")
                    
                    with gr.Row():
                        ref_audio = gr.Audio(
                            label="Reference Audio (Upload reference audio file)", 
                            type="filepath"
                        )
                        ref_text = gr.Textbox(
                            label="Reference Text (Text content corresponding to reference audio)", 
                            placeholder="Text corresponding to reference audio...",
                            lines=2
                        )
                
                with gr.Column():
                    gr.Markdown("### Parameters")
                    
                    target_rms = gr.Slider(
                        label="Target Volume (Audio volume normalization value)", 
                        minimum=0.01, 
                        maximum=1.0, 
                        value=0.1,
                        step=0.01
                    )
                    
                    nfe_step = gr.Slider(
                        label="Denoising Steps (Diffusion model denoising steps)", 
                        minimum=1, 
                        maximum=100, 
                        value=32,
                        step=1
                    )
                    
                    speed = gr.Slider(
                        label="Speech Speed (Speech playback speed)", 
                        minimum=0.1, 
                        maximum=3.0, 
                        value=1.0,
                        step=0.1
                    )
            
            synthesize_btn = gr.Button("üéµ Start Synthesis", variant="primary")
            
            with gr.Row():
                output_audio = gr.Audio(label="Synthesis Result", type="filepath")
                synthesis_status = gr.Textbox(label="Synthesis Status", interactive=False)
            
            # Connect sample text buttons
            for btn, sample_text in sample_text_buttons:
                btn.click(
                    fn=update_sample_text,
                    inputs=[gr.State(sample_text)],
                    outputs=[text_input]
                )
            
            # Connect sample audio buttons
            sample_audio_male_btn.click(
                fn=update_sample_audio_male,
                inputs=[dialect_choice],
                outputs=[ref_audio, ref_text]
            )
            
            sample_audio_female_btn.click(
                fn=update_sample_audio_female,
                inputs=[dialect_choice],
                outputs=[ref_audio, ref_text]
            )
            
            synthesize_btn.click(
                fn=synthesize_interface,
                inputs=[
                    text_input, dialect_choice, ref_audio, ref_text,
                    target_rms, nfe_step, speed
                ],
                outputs=[output_audio, synthesis_status]
            )
        
        with gr.Tab("User Guide"):
            gr.Markdown("""
            ## üìñ User Guide
            
            ### 1. Model Information
            - **Model Status**: System automatically preloads model at startup
            - **Configuration**: Model parameters are preset in the script
            - **MoE Architecture**: Supports Mixture of Experts model inference
            
            ### 2. Frontend Processing
            - **Input Text**: Supports Chinese text, automatic frontend processing
            - **Dialect Selection**: Supports multiple Chinese dialects
            - **Output**: Provides processed phonetic representation and IPA format
            
            ### 3. Speech Synthesis
            - **Sample Texts**: Click sample text buttons to auto-fill input
            - **Input Text**: Supports Chinese text, automatic frontend processing
            - **Dialect Selection**: Supports multiple Chinese dialects
            - **Reference Audio**: Upload clear reference audio file (WAV format recommended)
            - **Reference Text**: Enter text content corresponding to reference audio
            - **Sample Audio**: Click "Use Sample Audio" to load dialect-specific reference
            
            ### 4. Supported Dialects
            """)
            
            dialect_info = gr.DataFrame(
                value=[
                    ["putonghua", "Mandarin Chinese"],
                    ["chengdu", "Chengdu Dialect"],
                    ["gaoxiong", "Kaohsiung Dialect"], 
                    ["shanghai", "Shanghai Dialect"],
                    ["shijiazhuang", "Shijiazhuang Dialect"],
                    ["wuhan", "Wuhan Dialect"],
                    ["xian", "Xi'an Dialect"],
                    ["zhengzhou", "Zhengzhou Dialect"]
                ],
                headers=["Dialect Code", "Dialect Name"],
                interactive=False
            )
            
            gr.Markdown("""
            ### 5. Notes
            - Ensure reference audio has good quality with minimal noise
            - Reference text must exactly match audio content
            - Model loading is required for first-time use
            - Synthesis time depends on text length and hardware performance
            - Use sample texts and reference audios for quick testing
            """)
    
    return demo

if __name__ == "__main__":
    # Command line arguments
    parser = argparse.ArgumentParser(description="Dialect TTS Gradio Interface")
    parser.add_argument("--port", type=int, default=7860, help="Service port")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="Service host")
    parser.add_argument("--share", action="store_true", help="Create public link")
    args = parser.parse_args()
    
    # Create and launch interface
    demo = create_gradio_interface()
    print("Starting Dialect TTS Gradio Interface...")
    print(f"Service address: http://{args.host}:{args.port}")
    
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
        inbrowser=True
    )
